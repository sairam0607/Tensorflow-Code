{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defing the parameters for liner regression\n",
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a place holder \n",
    "X = tf.placeholder(tf.float32, [batch_size, 784], name = \"image\")\n",
    "Y = tf.placeholder(tf.float32, [bacth_size, 10] , name = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the weights and bias \n",
    "w = tf.Variable(tf.random_normal(shape = [784, 10], stddev = 0.01), name = \"weights\")\n",
    "b = tf.Variable(tf.zeros([1,10]), name = \"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate the score\n",
    "logits = tf.matmul(X, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy and cost function  and bias\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = Y)\n",
    "loss = tf.reduce_mean(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the optimization \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"GradientDescent_1\"\n",
      "op: \"NoOp\"\n",
      "input: \"^GradientDescent_1/update_weights_1/ApplyGradientDescent\"\n",
      "input: \"^GradientDescent_1/update_bias_1/ApplyGradientDescent\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.8455\n",
      "Test accuracy is 0.8549\n",
      "Test accuracy is 0.8605\n",
      "Test accuracy is 0.8638\n",
      "Test accuracy is 0.8684\n",
      "Test accuracy is 0.8699\n",
      "Test accuracy is 0.8727\n",
      "Test accuracy is 0.8747\n",
      "Test accuracy is 0.8775\n",
      "Test accuracy is 0.879\n",
      "Test accuracy is 0.8798\n",
      "Test accuracy is 0.8803\n",
      "Test accuracy is 0.8815\n",
      "Test accuracy is 0.8833\n",
      "Test accuracy is 0.8841\n",
      "Test accuracy is 0.8855\n",
      "Test accuracy is 0.8865\n",
      "Test accuracy is 0.8882\n",
      "Test accuracy is 0.8877\n",
      "Test accuracy is 0.8883\n"
     ]
    }
   ],
   "source": [
    "# run optimization and cost\n",
    "loss_history = []\n",
    "acc_history = []\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    n_batches = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(n_epochs):\n",
    "        for _ in range(n_batches):\n",
    "            X_batch, Y_batch = mnist.train.next_batch(batch_size)\n",
    "            _, loss_value = sess.run([optimizer, loss], feed_dict={X: X_batch, Y:Y_batch})\n",
    "        loss_history.append(loss_value)\n",
    "        \n",
    "        # Check validation accuracy    \n",
    "        n_v_batches = int(mnist.validation.num_examples/batch_size)\n",
    "        total_correct_preds = 0\n",
    "        for j in range(n_v_batches):\n",
    "            X_batch, Y_batch = mnist.validation.next_batch(batch_size)\n",
    "            _, loss_batch, logits_batch = sess.run([optimizer, loss, logits], feed_dict={X: X_batch, Y:Y_batch})\n",
    "            preds = tf.nn.softmax(logits_batch)\n",
    "            correct_preds = tf.equal(tf.argmax(preds, 1), tf.argmax(Y_batch, 1))\n",
    "            accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "            total_correct_preds += sess.run(accuracy)\n",
    "        validation_accuracy = total_correct_preds/mnist.validation.num_examples\n",
    "        acc_history.append(validation_accuracy)\n",
    "        \n",
    "        \n",
    "        # test the model\n",
    "        n_batches = int(mnist.test.num_examples/batch_size)\n",
    "        total_correct_preds = 0\n",
    "        for i in range(n_batches):\n",
    "            X_batch, Y_batch = mnist.test.next_batch(batch_size)\n",
    "            logits_batch = sess.run(logits, feed_dict= {X: X_batch, Y: Y_batch})\n",
    "            preds = tf.nn.softmax(logits_batch)\n",
    "            correct_preds = tf.equal(tf.argmax(preds,1), tf.argmax(Y_batch, 1))\n",
    "            accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "            total_correct_preds += sess.run(accuracy)\n",
    "        print(\"Test accuracy is {0}\".format(total_correct_preds/mnist.test.num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
