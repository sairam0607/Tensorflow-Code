{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a network that has only one LSTM cell. We have to pass 2 elemnts to LSTM, the prv_output and prv_state, so called, h and c. Therefore, we initialize a state vector, state. Here, state is a tuple with 2 elements, each one is of size [1 x 4], one for passing prv_output to next time step, and another for passing the prv_state to next time stamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'zeros:0' shape=(2, 4) dtype=float32>,\n",
       " <tf.Tensor 'zeros:0' shape=(2, 4) dtype=float32>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_CELL_SIZE = 4 # output size (dimension) which is same as hidden size in the cell\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(LSTM_CELL_SIZE, state_is_tuple = True)\n",
    "state = (tf.zeros([2, LSTM_CELL_SIZE]),)* 2\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let define a sample input. In this example, batch_size =2,and seq_len= 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  2.  3.  4.  3.  2.]\n",
      " [ 3.  2.  2.  2.  2.  2.]]\n"
     ]
    }
   ],
   "source": [
    "sample_input = tf.constant([[1,2,3,4,3,2], [3,2,2,2,2,2]], dtype = tf.float32)\n",
    "print(sess.run(sample_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can pass the input to lstm_cell, and check the new state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMStateTuple(c=array([[-0.27207065, -0.14977001, -0.50924844, -0.04473792],\n",
      "       [-0.51826453,  0.13118115, -0.20965381, -0.06719033]], dtype=float32), h=array([[-0.00298158, -0.06040691, -0.2331679 , -0.00418494],\n",
      "       [-0.01149935,  0.09326159, -0.11418024, -0.01398612]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"LSTM_sample1\"):\n",
    "    output, state_new = lstm_cell(sample_input, state)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(state_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the states has 2 parts, the new state, c, and also the output, h. Lets check the output again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00298158 -0.06040691 -0.2331679  -0.00418494]\n",
      " [-0.01149935  0.09326159 -0.11418024 -0.01398612]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked LSTM basecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about if we want to have a RNN with stacked LSTM? For example, a 2-layer LSTM. In this case, the output of the first layer will become the input of the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## let start the new session \n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM_CELL_SIZE = 4 # 4 hidden nodes = state_dim  = the output_dim\n",
    "input_dim = 6\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cells = []\n",
    "for _ in range(num_layers):\n",
    "    cell = tf.contrib.rnn.LSTMCell(LSTM_CELL_SIZE)\n",
    "    cells.append(cell)\n",
    "    stacked_lstm = tf.contrib.rnn.MultiRNNCell(cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, ?, 6), dtype=float32) Tensor(\"rnn/transpose:0\", shape=(?, ?, 4), dtype=float32) LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(?, 4) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(?, 4) dtype=float32>)\n"
     ]
    }
   ],
   "source": [
    "data = tf.placeholder(tf.float32, [None, None, input_dim])\n",
    "output, state = tf.nn.dynamic_rnn(cell, data, dtype = tf.float32)\n",
    "print(data, output, state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say the input sequence length is 3, and the dimensionality of the inputs is 6. The input should be a Tensor of shape: [batch_size, max_time, dimension], in our case it would be (2, 3, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 2, 3, 4, 3, 2], [1, 2, 1, 1, 1, 2], [1, 2, 2, 2, 2, 2]],\n",
       " [[1, 2, 3, 4, 3, 2], [3, 2, 2, 1, 1, 2], [0, 0, 0, 0, 3, 2]]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Batch size x time steps x features.\n",
    "sample_input = [[[1,2,3,4,3,2], [1,2,1,1,1,2],[1,2,2,2,2,2]],[[1,2,3,4,3,2],[3,2,2,1,1,2],[0,0,0,0,3,2]]]\n",
    "sample_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.05511501,  0.01852267, -0.00904508, -0.19907627],\n",
       "        [-0.01939808,  0.02371921, -0.01738074, -0.03937931],\n",
       "        [-0.06129809,  0.02666961, -0.02447925, -0.04834963]],\n",
       "\n",
       "       [[-0.05511501,  0.01852267, -0.00904508, -0.19907627],\n",
       "        [-0.05639194,  0.00520131, -0.00815779,  0.09399685],\n",
       "        [-0.1300499 ,  0.12428377, -0.03200072,  0.08908086]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(output, feed_dict={data: sample_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
